{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maheenunzeelah/21k4177and21k4176sNLPProject/blob/main/n_gram_Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "\n",
        "# Load spaCy's English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"Tokenize text using spaCy and filter out punctuation and spaces.\"\"\"\n",
        "    doc = nlp(text)\n",
        "    return [token.text.lower() for token in doc if not token.is_punct and not token.is_space]\n",
        "\n",
        "def train_ngram_model(text, n):\n",
        "    tokens = tokenize(text)\n",
        "    ngrams = {}\n",
        "    context_counts = {}\n",
        "\n",
        "    for i in range(len(tokens) - n + 1):\n",
        "        context = tuple(tokens[i:i+n-1])\n",
        "        next_word = tokens[i+n-1]\n",
        "\n",
        "        # Initialize the dictionary for the context if it doesn't exist\n",
        "        if context not in ngrams:\n",
        "            ngrams[context] = {}\n",
        "            context_counts[context] = 0\n",
        "\n",
        "        # Update the next_word count for this context\n",
        "        if next_word not in ngrams[context]:\n",
        "            ngrams[context][next_word] = 0\n",
        "\n",
        "        ngrams[context][next_word] += 1\n",
        "        context_counts[context] += 1\n",
        "\n",
        "    return ngrams, context_counts\n",
        "\n",
        "def predict_next(ngrams, context_counts, context):\n",
        "    \"\"\"\n",
        "    Given a context (list of words), return a probability distribution of next words.\n",
        "    \"\"\"\n",
        "    context = tuple(word.lower() for word in context)\n",
        "    counts = ngrams.get(context)\n",
        "\n",
        "    if not counts:\n",
        "        return {}\n",
        "    total = float(context_counts[context])\n",
        "\n",
        "    return {word: count/total for word, count in counts.items()}\n",
        "\n",
        "def generate_text(ngrams, context_counts, seed, n, length=10):\n",
        "    \"\"\"\n",
        "    Generate text starting from a seed context.\n",
        "    \"\"\"\n",
        "    seed = [word.lower() for word in seed]  # Ensure seed is in lowercase\n",
        "\n",
        "\n",
        "    if len(seed) != n - 1:\n",
        "        raise ValueError(f\"Seed must have {n-1} words.\")\n",
        "\n",
        "    output = seed.copy()\n",
        "    for _ in range(length):\n",
        "        context = tuple(output[-(n-1):])\n",
        "        probs = predict_next(ngrams, context_counts, context)\n",
        "        if not probs:\n",
        "            break  # no predictions available\n",
        "        next_word = random.choices(list(probs.keys()), weights=probs.values())[0]\n",
        "        output.append(next_word)\n",
        "    return ' '.join(output)\n",
        "\n",
        "sample_text = (\n",
        "        \"Natural language processing with spaCy is both powerful and efficient. \"\n",
        "        \"Language models can be built using n-grams to predict the next word in a sentence. \"\n",
        "        \"The n-gram language model is a simple yet effective approach.\"\n",
        "    )\n",
        "\n",
        "  # Set n for the n-gram model (e.g., 3 for trigram)\n",
        "n = 3\n",
        "ngrams, context_counts = train_ngram_model(sample_text, n)\n",
        "\n",
        "\n",
        "# Define a seed (must have n-1 words)\n",
        "seed = ['Natural','language']\n",
        "\n",
        "# # Predict next word probabilities for the seed\n",
        "predictions = predict_next(ngrams, context_counts, seed)\n",
        "print(\"Predicted probabilities for next word:\", predictions)\n",
        "\n",
        "# # Generate text starting from the seed\n",
        "generated = generate_text(ngrams, context_counts, seed, n, length=15)\n",
        "print(\"\\nGenerated text:\\n\", generated)\n"
      ],
      "metadata": {
        "id": "2Tf1mkX0jWUh",
        "outputId": "f3d80fff-adb2-448f-e526-6549c587d4a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted probabilities for next word: {'processing': 1.0}\n",
            "\n",
            "Generated text:\n",
            " natural language processing with spacy is both powerful and efficient language models can be built using n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRt9yvQ7jW4Y"
      },
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}