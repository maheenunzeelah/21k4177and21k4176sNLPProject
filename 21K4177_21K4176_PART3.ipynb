{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2bvCFvRiteH",
        "outputId": "bf8961ab-cf47-4fe8-8fa6-f25cdd786b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from collections import defaultdict\n",
        "from sklearn.utils import shuffle\n",
        "import spacy\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from spacy import displacy\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.metrics import  accuracy_score,classification_report, confusion_matrix  #for visualizing tree \n",
        "import scipy\n",
        "from scipy.sparse import hstack\n",
        "from scipy.sparse import coo_matrix\n",
        "from scipy import sparse\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle as cPickle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense,Concatenate, TimeDistributed,Layer\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed"
      ],
      "metadata": {
        "id": "1NB9BapIizeI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXxH_XD9i_83",
        "outputId": "14137a96-e6e9-4877-9c6f-466314fee320"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "id": "YqguiYAYjB2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " summ_df = pd.read_csv('/content/drive/MyDrive/summ_df.csv',index_col=0)"
      ],
      "metadata": {
        "id": "GBlcyQmpjEtf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvgIStO1jPsw",
        "outputId": "9fcf69aa-c188-4234-bcce-b1e33c72a3c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1009 entries, 0 to 1008\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   titles     1004 non-null   object\n",
            " 1   abstracts  924 non-null    object\n",
            " 2   sections   946 non-null    object\n",
            " 3   summaries  1009 non-null   object\n",
            " 4   citations  1009 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 47.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "zLuohLXDjqVj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "XsmE6vxAjrwC",
        "outputId": "2ed5924f-f7ab-4383-e426-04870772344d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0          TnT - A Statistical Part-Of-Speech Tagger   \n",
              "1  Sentence Reduction For Automatic Text Summariz...   \n",
              "2  Advances In Domain Independent Linear Text Seg...   \n",
              "3  A Simple Approach To Building Ensembles Of Nai...   \n",
              "4                  A Maximum-Entropy-Inspired Parser   \n",
              "\n",
              "                                           abstracts  \\\n",
              "0  Trigrams'n'Tags (TnT) is an efficient statisti...   \n",
              "1  Figure 2: Sample sentence and parse tree we ha...   \n",
              "2  This paper describes a method for linear text ...   \n",
              "3  This paper presents a corpus-based approach to...   \n",
              "4  We present a new parser for parsing down to Pe...   \n",
              "\n",
              "                                            sections  \\\n",
              "0  A large number of current language processing ...   \n",
              "1  Current automatic summarizers usually rely on ...   \n",
              "2  Even moderately long documents typically addre...   \n",
              "3  Word sense disambiguation is often cast as a p...   \n",
              "4  We present a new parser for parsing down to Pe...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  TnT - A Statistical Part-Of-Speech Tagger\\nTri...   \n",
              "1  Sentence Reduction For Automatic Text Summariz...   \n",
              "2  Advances In Domain Independent Linear Text Seg...   \n",
              "3  A Simple Approach To Building Ensembles Of Nai...   \n",
              "4  A Maximum-Entropy-Inspired Parser\\nWe present ...   \n",
              "\n",
              "                                           citations  \n",
              "0  The sentences in the DSO collection were tagge...  \n",
              "1   In fact, professional abstractors tend to use...  \n",
              "2  Choi (2000) used the rank of the cosine, rathe...  \n",
              "3  We have presented an ensemble approach to word...  \n",
              "4   As a benchmark VPC extraction system, we use ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5288bcd6-73b5-4d2c-a768-c7702477d32c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>abstracts</th>\n",
              "      <th>sections</th>\n",
              "      <th>summaries</th>\n",
              "      <th>citations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TnT - A Statistical Part-Of-Speech Tagger</td>\n",
              "      <td>Trigrams'n'Tags (TnT) is an efficient statisti...</td>\n",
              "      <td>A large number of current language processing ...</td>\n",
              "      <td>TnT - A Statistical Part-Of-Speech Tagger\\nTri...</td>\n",
              "      <td>The sentences in the DSO collection were tagge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence Reduction For Automatic Text Summariz...</td>\n",
              "      <td>Figure 2: Sample sentence and parse tree we ha...</td>\n",
              "      <td>Current automatic summarizers usually rely on ...</td>\n",
              "      <td>Sentence Reduction For Automatic Text Summariz...</td>\n",
              "      <td>In fact, professional abstractors tend to use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Advances In Domain Independent Linear Text Seg...</td>\n",
              "      <td>This paper describes a method for linear text ...</td>\n",
              "      <td>Even moderately long documents typically addre...</td>\n",
              "      <td>Advances In Domain Independent Linear Text Seg...</td>\n",
              "      <td>Choi (2000) used the rank of the cosine, rathe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A Simple Approach To Building Ensembles Of Nai...</td>\n",
              "      <td>This paper presents a corpus-based approach to...</td>\n",
              "      <td>Word sense disambiguation is often cast as a p...</td>\n",
              "      <td>A Simple Approach To Building Ensembles Of Nai...</td>\n",
              "      <td>We have presented an ensemble approach to word...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A Maximum-Entropy-Inspired Parser</td>\n",
              "      <td>We present a new parser for parsing down to Pe...</td>\n",
              "      <td>We present a new parser for parsing down to Pe...</td>\n",
              "      <td>A Maximum-Entropy-Inspired Parser\\nWe present ...</td>\n",
              "      <td>As a benchmark VPC extraction system, we use ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5288bcd6-73b5-4d2c-a768-c7702477d32c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5288bcd6-73b5-4d2c-a768-c7702477d32c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5288bcd6-73b5-4d2c-a768-c7702477d32c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df=summ_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "qqtEOlHLjtLc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df[\"text\"] = summ_df[[\"citations\", \"abstracts\"]].apply(\" \".join, axis=1)\n",
        "display(summ_df[\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ntKqNJ8KkujW",
        "outputId": "a8f01518-7df2-4b45-e1a9-74273c7c4dc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"The sentences in the DSO collection were tagged with parts of speech using TnT (Brants, 2000) trained on the Brown Corpus itself.  The English POS-tagging has been carried out using freely available TNT tagger (Brants, 2000). This proposition is quite viable as statistical POS taggers like TnT (Brants, 2000) are available. We use TnT (Brants, 2000), a second order Markov Model tagger. For PoS tagging and lemmatization, we combine GENIA (with its built-in, occasionally deviant to kenizer) and TnT (Brants, 2000), which operates on pre-tokenized inputs but in its default models trained on financial news from the Penn Tree bank. Tag the tokens with PTB-style POS tags using a tagger (Brants, 2000). For example, Petrov et al (2012) build supervised POS taggers for 22 languages using the TNT tagger (Brants, 2000), with an average accuracy of 95.2%. Forun aligned words, we simply assign a random POS and very low probability, which does not substantially affect transition probability estimates. In Step 6 we build a tagger by feeding the es ti mated emission and transition probabilities into the TNT tagger (Brants, 2000), an implementation of a trigram HMM tagger. based on tree-structures of various complexity in the tree-adjoining grammar model. Using such tags, Brants (2000) has achieved the automated tagging of a syntactic-structure-based set of grammatical function tags including phrase-chunk and syntactic-role modifiers trained in supervised mode from a tree bank of German. We also incorporated part-of speech tagging, using the TnT tagger (Brants, 2000) retrained on the GENIA corpus gold standard part of-speech tagging. POS Majority lexical type noun count-noun-le c-n-f verb trans-nerg-str-verb-le haben-auxf adj adj-non-prd-le adv intersect-adv-le Table 5: POS tags to lexical types mapping Again for comparison, we have built another simple baseline model using the TnT POS tagger (Brants, 2000). The texts were POS-tagged using TnT (Brants,2000). The freely-available POS lexicon from Sharoff et al (2008), specifically the file for the POS tagger TnT (Brants, 2000), contains full words (239,889 unique forms), with frequency information. We use a corpus of 5 million words automatically tagged by TnT (Brants, 2000) and freely available online (Sharoff et al, 2008). Because we want to make linguistically-informed corruptions, we corrupt only the words we have information for, identifying the words in the corpus which are found in the lexicon with the appropriate POS tag. We also select only words which have inflectional morphology: nouns, verbs, adjectives, pronouns, and numerals.7 4.2.1 Determining word properties (step 1) We use the POS tag to restrict the properties of a word, regardless of how exactly we corrupt it. To POS tag, we use the HMM tagger TnT (Brants, 2000) with the model from http: //corpus.leeds.ac.uk/mocky/. After finishing the corrections, we experimented with training and testing the TnT tagger (Brants,2000) on the& quot; old& quot; and on the& quot; corrected& quot; version of NEGRA?. To make them useful, the necessary preprocessing steps must have been done. The texts were first automatically segmented and tokenized and then they were part-of-speech tagged by TnT tagger (Brants, 2000), which was trained on the respective WILS training data. POS tags, on the other, represent more of a challenge with only 91.6% NORM LEMMA POS Agreed tokens (out of 57,845) 56,052 55,217 52,959 Accuracy (%) 96.9% 95.5% 91.6% Table 3: Inter-annotator agreement agreement between two annotators, which is cons id erably lower than the agreement level reported for annotating a corpus of modern German using STTS, at 98.6% (Brants, 2000a). We further plan to retrain state-of the-art POS taggers such as the TreeTagger and TnT Tagger (Brants, 2000b) on our data. Finally, we plan to investigate how linguistic annotations can be automatically integrated in the TEI annotated version of the corpus to produce TEI con formant output.  Trigrams'n'Tags (TnT) is an efficient statistical part-of-speech tagger. Contrary to claims found elsewhere in the literature, we argue that a tagger based on Markov models performs at least as well as other current approaches, including the Maximum Entropy framework. A recent comparison has even shown that TnT performs significantly better for the tested corpora. We describe the basic model of TnT, the techniques used for smoothing and for handling unknown words. Furthermore, we present evaluations on two corpora. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install bert-extractive-summarizer\n",
        "# !pip install summarizer"
      ],
      "metadata": {
        "id": "5xdU7-0uJTjd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from summarizer import summarize"
      ],
      "metadata": {
        "id": "eq2eJRHmLZUd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3-jnNXpCJkaK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_model = Summarizer()\n",
        "# bert_summary = ''.join(bert_model(summ_df[\"text\"][0], min_length=50))\n",
        "# print(bert_summary)"
      ],
      "metadata": {
        "id": "wxuSpCEXEEME"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bert_summary)"
      ],
      "metadata": {
        "id": "PvZoQy6-KDc3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df[\"short_text\"]=pd.Series([])"
      ],
      "metadata": {
        "id": "adh0ec3tErFk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(summ_df)):\n",
        "  summ=\" \".join(summarize(summ_df[\"titles\"][i],summ_df[\"text\"][i],15))\n",
        "  summ_df[\"short_text\"][i]=summ"
      ],
      "metadata": {
        "id": "7m8nhYjaMG1L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JD55aMbHMXSu",
        "outputId": "ab48d673-1c2f-4394-bcff-4f05134609cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0          TnT - A Statistical Part-Of-Speech Tagger   \n",
              "1  Sentence Reduction For Automatic Text Summariz...   \n",
              "2  Advances In Domain Independent Linear Text Seg...   \n",
              "3  A Simple Approach To Building Ensembles Of Nai...   \n",
              "4                  A Maximum-Entropy-Inspired Parser   \n",
              "\n",
              "                                           abstracts  \\\n",
              "0  Trigrams'n'Tags (TnT) is an efficient statisti...   \n",
              "1  Figure 2: Sample sentence and parse tree we ha...   \n",
              "2  This paper describes a method for linear text ...   \n",
              "3  This paper presents a corpus-based approach to...   \n",
              "4  We present a new parser for parsing down to Pe...   \n",
              "\n",
              "                                            sections  \\\n",
              "0  A large number of current language processing ...   \n",
              "1  Current automatic summarizers usually rely on ...   \n",
              "2  Even moderately long documents typically addre...   \n",
              "3  Word sense disambiguation is often cast as a p...   \n",
              "4  We present a new parser for parsing down to Pe...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  TnT - A Statistical Part-Of-Speech Tagger\\nTri...   \n",
              "1  Sentence Reduction For Automatic Text Summariz...   \n",
              "2  Advances In Domain Independent Linear Text Seg...   \n",
              "3  A Simple Approach To Building Ensembles Of Nai...   \n",
              "4  A Maximum-Entropy-Inspired Parser\\nWe present ...   \n",
              "\n",
              "                                           citations  \\\n",
              "0  The sentences in the DSO collection were tagge...   \n",
              "1   In fact, professional abstractors tend to use...   \n",
              "2  Choi (2000) used the rank of the cosine, rathe...   \n",
              "3  We have presented an ensemble approach to word...   \n",
              "4   As a benchmark VPC extraction system, we use ...   \n",
              "\n",
              "                                                text  \\\n",
              "0  The sentences in the DSO collection were tagge...   \n",
              "1   In fact, professional abstractors tend to use...   \n",
              "2  Choi (2000) used the rank of the cosine, rathe...   \n",
              "3  We have presented an ensemble approach to word...   \n",
              "4   As a benchmark VPC extraction system, we use ...   \n",
              "\n",
              "                                          short_text  \n",
              "0  The sentences in the DSO collection were tagge...  \n",
              "1  Examples include text summarisation (Jing 2000...  \n",
              "2  Choi (2000) used the rank of the cosine, rathe...  \n",
              "3  We have presented an ensemble approach to word...  \n",
              "4   As a benchmark VPC extraction system, we use ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efebcaf4-1a4f-4e25-8c75-6144182a755b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>abstracts</th>\n",
              "      <th>sections</th>\n",
              "      <th>summaries</th>\n",
              "      <th>citations</th>\n",
              "      <th>text</th>\n",
              "      <th>short_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TnT - A Statistical Part-Of-Speech Tagger</td>\n",
              "      <td>Trigrams'n'Tags (TnT) is an efficient statisti...</td>\n",
              "      <td>A large number of current language processing ...</td>\n",
              "      <td>TnT - A Statistical Part-Of-Speech Tagger\\nTri...</td>\n",
              "      <td>The sentences in the DSO collection were tagge...</td>\n",
              "      <td>The sentences in the DSO collection were tagge...</td>\n",
              "      <td>The sentences in the DSO collection were tagge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence Reduction For Automatic Text Summariz...</td>\n",
              "      <td>Figure 2: Sample sentence and parse tree we ha...</td>\n",
              "      <td>Current automatic summarizers usually rely on ...</td>\n",
              "      <td>Sentence Reduction For Automatic Text Summariz...</td>\n",
              "      <td>In fact, professional abstractors tend to use...</td>\n",
              "      <td>In fact, professional abstractors tend to use...</td>\n",
              "      <td>Examples include text summarisation (Jing 2000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Advances In Domain Independent Linear Text Seg...</td>\n",
              "      <td>This paper describes a method for linear text ...</td>\n",
              "      <td>Even moderately long documents typically addre...</td>\n",
              "      <td>Advances In Domain Independent Linear Text Seg...</td>\n",
              "      <td>Choi (2000) used the rank of the cosine, rathe...</td>\n",
              "      <td>Choi (2000) used the rank of the cosine, rathe...</td>\n",
              "      <td>Choi (2000) used the rank of the cosine, rathe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A Simple Approach To Building Ensembles Of Nai...</td>\n",
              "      <td>This paper presents a corpus-based approach to...</td>\n",
              "      <td>Word sense disambiguation is often cast as a p...</td>\n",
              "      <td>A Simple Approach To Building Ensembles Of Nai...</td>\n",
              "      <td>We have presented an ensemble approach to word...</td>\n",
              "      <td>We have presented an ensemble approach to word...</td>\n",
              "      <td>We have presented an ensemble approach to word...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A Maximum-Entropy-Inspired Parser</td>\n",
              "      <td>We present a new parser for parsing down to Pe...</td>\n",
              "      <td>We present a new parser for parsing down to Pe...</td>\n",
              "      <td>A Maximum-Entropy-Inspired Parser\\nWe present ...</td>\n",
              "      <td>As a benchmark VPC extraction system, we use ...</td>\n",
              "      <td>As a benchmark VPC extraction system, we use ...</td>\n",
              "      <td>As a benchmark VPC extraction system, we use ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efebcaf4-1a4f-4e25-8c75-6144182a755b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efebcaf4-1a4f-4e25-8c75-6144182a755b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efebcaf4-1a4f-4e25-8c75-6144182a755b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def text_preprocess(text):\n",
        "# #Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\n",
        "#     clean_text_array = []\n",
        "# #     print(text)\n",
        "#     stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "#     tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "#     for par in text:\n",
        "# #         print(par)\n",
        "#         tmp = []\n",
        "#         sentences = nltk.sent_tokenize(par)\n",
        "#         for sent in sentences:\n",
        "#             sent = sent.lower()\n",
        "#             tokens = tokenizer.tokenize(sent)\n",
        "#             filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n",
        "# #             print(filtered_words)\n",
        "#             wordnet_lemmatizer = WordNetLemmatizer() # with use of morphological analysis of words\n",
        "#             text_lemma = [wordnet_lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "# #             print(text_lemma)\n",
        "#             tmp.extend(text_lemma)\n",
        "#         clean_text_array.append(tmp)\n",
        "#     return clean_text_array    "
      ],
      "metadata": {
        "id": "d6JkUK9wkx_y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "TX9K_aTGmktQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "def text_cleaner(text,num):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    if(num==0):\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    else:\n",
        "        tokens=newString.split()\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                                 #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "metadata": {
        "id": "UOypPG-9mJ_N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summ_df['short_text']=text_preprocess(summ_df['short_text'])\n",
        "# summ_df['short_text']=summ_df['short_text'].apply(lambda l: \" \".join(l))"
      ],
      "metadata": {
        "id": "oPAdM-tjk0-a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summ_df['summaries']=text_preprocess(summ_df['summaries'])\n",
        "# summ_df['summaries']=summ_df['summaries'].apply(lambda l: \" \".join(l))"
      ],
      "metadata": {
        "id": "ld7jFcV3k2z6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = []\n",
        "for t in summ_df['short_text']:\n",
        "    cleaned_text.append(text_cleaner(t,0)) "
      ],
      "metadata": {
        "id": "SJuhVDuDlVc5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaned_text[:5]  "
      ],
      "metadata": {
        "id": "PBIFE9-rm4tL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_summary = []\n",
        "for t in summ_df['summaries']:\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "metadata": {
        "id": "75DFm2Fem7rz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaned_summary[:10]"
      ],
      "metadata": {
        "id": "OBCbY30lnDDt"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df['cleaned_text']=cleaned_text\n",
        "summ_df['cleaned_summary']=cleaned_summary"
      ],
      "metadata": {
        "id": "EfKnPJOKnDy8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df.replace('', np.nan, inplace=True)\n",
        "summ_df.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "ofyzT_nfnKyK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_df[\"cleaned_text\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "N5zzt276HQsM",
        "outputId": "9ee7a4e6-fdd2-4a8c-995d-b3f9c5f2e0c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sentences dso collection tagged parts speech using tnt trained brown corpus english pos tagging carried using freely available tnt tagger proposition quite viable statistical pos taggers like tnt available use tnt second order markov model tagger tag tokens ptb style pos tags using tagger example petrov et al build supervised pos taggers languages using tnt tagger average accuracy step build tagger feeding es ti mated emission transition probabilities tnt tagger implementation trigram hmm tagger also incorporated part speech tagging using tnt tagger retrained genia corpus gold standard part speech tagging freely available pos lexicon sharoff et al specifically file pos tagger tnt contains full words frequency information use corpus million words automatically tagged tnt freely available online pos tag use hmm tagger tnt model http corpus leeds ac uk mocky finishing corrections experimented training testing tnt tagger quot old quot quot corrected quot version negra texts first automatically segmented tokenized part speech tagged tnt tagger trained respective wils training data plan retrain state art pos taggers treetagger tnt tagger data trigrams tags efficient statistical part speech tagger describe basic model tnt techniques used smoothing handling unknown words'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample = summ_df.sample(frac=0.05, random_state=2)"
      ],
      "metadata": {
        "id": "FA0vlXhZjv39"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in summ_df['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in summ_df['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "TczaoZEJlVDY",
        "outputId": "5b98a4a1-3de4-4e52-d9d8-2c109b0ade94"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample"
      ],
      "metadata": {
        "id": "eLp-ve2Qj-sm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt=0\n",
        "for i in summ_df['cleaned_text']:\n",
        "    if(len(i.split())<=400):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(summ_df['cleaned_text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6PaUZKin3X5",
        "outputId": "e39b0e26-6a55-457a-818a-19a368ac41be"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9989177489177489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt=0\n",
        "for i in summ_df['cleaned_summary']:\n",
        "    if(len(i.split())<=200):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(summ_df['cleaned_summary']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPvVaVmFkTdc",
        "outputId": "65cb8c4b-2382-41d3-fc33-69ea48422670"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8809523809523809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_text_len=400\n",
        "max_summary_len=200"
      ],
      "metadata": {
        "id": "S2iXJPo4nZ46"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text =np.array(summ_df['cleaned_text'])\n",
        "cleaned_summary=np.array(summ_df['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "metadata": {
        "id": "2GQ6KTPToD7P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "metadata": {
        "id": "SV6Aaav7oIlO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "l3QR3-0modx2",
        "outputId": "754a0763-2ca5-4e09-d6d5-814c9e671413"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'examples include text summarisation subtitle generation spoken transcripts information retrieval sentence compression task summarizing sentence retaining informational content remaining grammatical evaluation sentence reduction details used corpus sentences reduced forms human written abstracts overcome problem linguistic parsing generation systems used sentence condensation approaches knight marcu jing table shows sentence summary created using algorithm paper overcome problem linguistic parsing generation systems used sentence condensation approaches knight marcu jing sentence compression produces summary single sentence retains important information remaining grammatical figure sample sentence parse tree input sentence abcdehas parse tree shown figure human reduces sentence translated series decisions made along edges sentence parse tree shown figure extended sentence reduction program query based summarization adding another step algorithm measure relevance users queries phrases sentence ideally sentence reduction module interact modules summarization system researchers worked text simplifica tion problem usually involves simplifying text removing phrases conclusions future work present novel sentence reduction system removes extraneous phrases sentences extracted article text summarization focus work determining sentence particular context phrases sentence less important removed system makes intelligent reduction decisions based multiple sources knowledge including syntactic knowledge context probabilities computed corpus analysis future would like integrate sentence reduction system extraction based summarization systems one developed improve performance system introducing sources knowledge necessary reduction explore interesting applications reduction system'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"summary\"][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "N6Doq5oCoKnp",
        "outputId": "6497c140-adde-4dbb-b0d5-7aac6b866d0b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sostok sentence reduction for automatic text summarization we present novel sentence reduction system for automatically removing extraneous phrases from sentences that are extracted from document for summarization purpose the system uses multiple sources of knowledge to decide which phrases in an extracted sentence can be removed including syntactic knowledge context information and statistics computed from corpus which consists of examples written by human professionals reduction can significantly improve the conciseness of automatic summaries we study new method to remove extraneous phrase from sentences by using multiple source of knowledge to decide which phrase in the sentences can be removed in our approach decisions about which material to include delete in the sentence summaries do not rely on relative frequency information on words but rather on probability models of subtree deletions that are learned from corpus of parses for sentences and their summaries eostok'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0) "
      ],
      "metadata": {
        "id": "sAaAQkU4oLsP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "metadata": {
        "id": "soa8pG5TopiH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6wBUnblosrc",
        "outputId": "37fbc0f8-d7f6-4444-ee94-b9f9f7a482bb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 59.096705632306055\n",
            "Total Coverage of rare words: 5.880577276908924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "metadata": {
        "id": "NJpQ90Byouk0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "metadata": {
        "id": "_jWBWDS0oyKW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c9EEPRVoz7u",
        "outputId": "6c9304c9-88b8-444e-fea4-935c505bfdbc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary: 67.36016371077763\n",
            "Total Coverage of rare words: 7.552026177697082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "metadata": {
        "id": "mwPj9a3mo20J"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "metadata": {
        "id": "k05SkLCwo43V"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(Layer):\n",
        "\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "metadata": {
        "id": "7OhoCStro613"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2EUZUNno-N2",
        "outputId": "3fd7b4da-320e-45a5-fe22-515a5342fa21"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 400)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 400, 100)     385000      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 400, 300),   481200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 400, 300),   721200      ['lstm[0][0]']                   \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    191500      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 400, 300),   721200      ['lstm_1[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 300),  180300     ['lstm_2[0][0]',                 \n",
            " r)                              (None, None, 400))               'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 600)    0           ['lstm_3[0][0]',                 \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, None, 1915)  1150915     ['concat_layer[0][0]']           \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,312,515\n",
            "Trainable params: 4,312,515\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5), loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "TqRSOp6hpA7G"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_checkpoint_1 = ModelCheckpoint(filepath='summ_model__att_v2',\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "metadata": {
        "id": "uaLgxjpvpDqY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=5,callbacks=[tl_checkpoint_1,es],batch_size=48, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:\n",
        "                     , 1:]),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubS7akjapMC3",
        "outputId": "5bc94bea-5e1c-4c9c-99f2-e73661ed97f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.8762  \n",
            "Epoch 1: val_loss improved from inf to 3.74001, saving model to summ_model__att_v2\n",
            "16/16 [==============================] - 1330s 82s/step - loss: 3.8762 - val_loss: 3.7400\n",
            "Epoch 2/5\n",
            " 2/16 [==>...........................] - ETA: 20:28 - loss: 4.0277"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "SAkRw62TpkG4",
        "outputId": "8e4d5609-7e77-49f4-f85d-708780dbe486"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "metadata": {
        "id": "Defdnt1nAbRW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "611Hg3x4Aets"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        if(np.argmax(output_tokens[0, -1, :])==0):\n",
        "          sampled_token_index=np.argsort(output_tokens[0, -1, :])[-2]\n",
        "        else:  \n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "62sKIKmiAhBq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "metadata": {
        "id": "QwgSNqClAi_c"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x21Rm-JhAsfS",
        "outputId": "8f9ff4e8-3501-4337-aeec-8b877465213f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: socher et al socher et al present framework based recursive neural net works learns vector space representations multi word phrases sentences specifically related work deep learning neural networks successfully employed sentiment analysis sentiment domain adaptation analogous prediction task lin socher et al investigated predicting emotion reader text unlike socher et al utilize manually labeled texts learn meaning phrase compositionality focus learning meaning word namely word embedding massive distant supervised tweets recursive proven effective many sentiment analysis tasks learning compositionality automatically use two unsupervised recursive one source phrase target phrase details found providing richer representations meaning discrete representation approaches successfully applied tasks sentiment analysis topic classification word word similarity previous work classifying snippets include using pre defined polarity rules learning complex models parse trees socher et al introduce semi supervised approach uses recursive learn hierarchical structure sentiment distribution sentence introduce novel machine learning framework based recursive sentence level prediction sentiment label distributions sentiment prediction tasks representations outperform state art approaches commonly used datasets movie reviews without using pre defined sentiment lexica polarity rules also evaluate model ability predict sentiment distributions new dataset based experience project dataset consists personal user stories annotated multiple labels form multinomial distribution captures algorithm accurately predict distributions labels compared several competitive baselines \n",
            "Original summary: semi supervised recursive for predicting sentiment distributions we introduce novel machine learning framework based on recursive for sentence level prediction of sentiment label distributions our method learns vector space representations for multi word phrases in sentiment prediction tasks these representations outperform other state of the art approaches on commonly used datasets such as movie reviews without using any pre defined sentiment or polarity rules we also evaluate the model ability to predict sentiment distributions on new dataset based on from the experience project the dataset consists of user stories annotated with multiple labels which when form distribution that captures our algorithm can more accurately predict distributions over such labels compared to several competitive baselines we introduce semi supervised approach that uses recursive to learn the hierarchical structure and sentiment distribution of sentence \n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 640ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Predicted summary:  for for for for for for for for for for for the the the of of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "\n",
            "\n",
            "Review: comparing latter half experimental results parsing investigated similarities differences probabilistic models parsing generation features combinations previous work hpsg parsing similar results reported parsing accuracy around sentences results different parsing reported miyao tsujii span especially contributed accuracy paper use hpsg parser developed miyao tsujii addition hpsg grammar extracted hpsg treebank using corpus based procedure necessarily cover possible grammatical phenomena unseen text running hpsg parser described section development data without dependency constraints obtain similar values reported miyao tsujii examined sentences using phrase structure parser hpsg parser addition parsers compute deeper analyses predicate argument structures become available processing real world sentences first parsed sentences using hpsg parser obtain predicate argument structures hpsg parser used study et al based experiments compared model probabilistic hpsg model miyao tsujii paper reports development loglinear models disambiguation wide coverage hpsg parsing using techniques reduce estimation cost trained models using sections penn treebank series experiments empirically evaluated estimation techniques also examined performance disambiguation models parsing real world sentences \n",
            "Original summary: probabilistic disambiguation models for wide coverage hpsg parsing this paper reports the development of log linear models for the disambiguation in wide coverage hpsg parsing the estimation of log linear models requires high computational cost especially with wide coverage grammars using techniques to reduce the estimation cost we trained the models using of penn treebank series of experiments empirically evaluated the estimation techniques and also examined the performance of the disambiguation models on the parsing of real world sentences our hpsg parser computes analyses such as predicate argument structures we also introduce hybrid model where the probabilities of the previous model are by the super tagging probabilities instead of preliminary probabilistic model to help the process of estimation by filtering lexical entries \n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Predicted summary:  for for for for for for for for for for for the the the of of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "\n",
            "\n",
            "Review: examples include text summarisation generation spoken transcripts information retrieval sentence compression task summarizing sentence informational content remaining grammatical evaluation sentence reduction details used corpus sentences reduced forms human written abstracts overcome problem linguistic parsing generation systems used sentence condensation approaches knight marcu jing table shows sentence summary created using algorithm paper overcome problem linguistic parsing generation systems used sentence condensation approaches knight marcu jing sentence compression produces summary single sentence important information remaining grammatical figure sample sentence parse tree input sentence parse tree shown figure human reduces sentence translated series decisions made along edges sentence parse tree shown figure extended sentence reduction program query based summarization adding another step algorithm measure relevance users queries phrases sentence sentence reduction module interact modules summarization system researchers worked text tion problem usually involves text removing phrases conclusions future work present novel sentence reduction system removes extraneous phrases sentences extracted article text summarization focus work determining sentence particular context phrases sentence less important removed system makes intelligent reduction decisions based multiple sources knowledge including syntactic knowledge context probabilities computed corpus analysis future would like integrate sentence reduction system extraction based summarization systems one developed improve performance system introducing sources knowledge necessary reduction explore interesting applications reduction system \n",
            "Original summary: sentence reduction for automatic text summarization we present novel sentence reduction system for automatically phrases from sentences that are extracted from document for summarization purpose the system uses multiple sources of knowledge to which phrases in an extracted sentence can be including syntactic knowledge context information and statistics computed from corpus which consists of examples written by human reduction can significantly improve the of automatic summaries we study new method to remove phrase from sentences by using multiple source of knowledge to which phrase in the sentences can be in our approach decisions about which material to include in the sentence summaries do not rely on relative frequency information on words but rather on probability models of subtree that are learned from corpus of parses for sentences and their summaries \n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Predicted summary:  for for for for for for for for for for for the the the of of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8ZpONi5AwU9"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}